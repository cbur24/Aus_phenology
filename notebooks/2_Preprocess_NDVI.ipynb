{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6185d6-5015-4c74-a294-e3c3cea28081",
   "metadata": {},
   "source": [
    "# Preprocess NDVI\n",
    "\n",
    "Here we take our gridded NDVI data, interpolate to daily values, summarise over the ecoregions, then save the file as a pickle file.\n",
    "\n",
    "The NDVI data was already smoothed and interpolated to bi-weekly in another notebook\n",
    "\n",
    "We can then use the pickle file for extracting phenometrics in the next notebook.\n",
    "\n",
    "We do this because daily NDVI over Australia is a huge amount of data so it better if we only do this once and save the results.\n",
    "\n",
    "<!-- # current_debt = 615007+42778\n",
    "# lvr = 0.8\n",
    "# house_value = 790000\n",
    "# amount_to_pay_off = current_debt - (lvr*house_value)\n",
    "# amount_to_pay_off -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c7445-4b35-4c1a-b586-353f4a293c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import dask\n",
    "import pickle\n",
    "import warnings\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from odc.geo.xr import assign_crs\n",
    "from odc.geo.geom import Geometry\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdcf76-e699-4bfe-b891-07778afb22da",
   "metadata": {},
   "source": [
    "## Open a dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d301024-ebaa-4e7e-af5f-61275339ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/AusEFlux/src/')\n",
    "from _utils import start_local_dask\n",
    "client = start_local_dask()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f402f2d-ab13-41f3-8442-43722664c9d5",
   "metadata": {},
   "source": [
    "## Analysis Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c27f5-4dbd-40e2-904d-961b23786d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# product='AusENDVI-clim'\n",
    "# product='AusENDVI-clim_MCD43A4'\n",
    "# product='GIMMS-PKU'\n",
    "# product='GIMMS-PKU_2022'\n",
    "# product='GIMMSv1.1'\n",
    "# product='GIMMSv1.2'\n",
    "# product='MCD43A4'\n",
    "# product='Landsat'\n",
    "product='AusENDVI-clim_2000'\n",
    "\n",
    "ds_path = '/g/data/os22/chad_tmp/Aus_phenology/data/NDVI/NDVI_smooth_'+product+'.nc'\n",
    "\n",
    "# save_file = '/g/data/os22/chad_tmp/Aus_phenology/data/IBRA_regions_NDVI_timeseries.pkl'\n",
    "save_file = '/g/data/os22/chad_tmp/Aus_phenology/data/pickle/IBRA_subregions_NDVI_'+product+'.pkl'\n",
    "\n",
    "# ecoregions_file = '/g/data/os22/chad_tmp/Aus_phenology/data/vectors/IBRAv7_regions_modified.geojson'\n",
    "ecoregions_file = '/g/data/os22/chad_tmp/Aus_phenology/data/vectors/IBRAv7_subregions_modified.geojson'\n",
    "\n",
    "# var='REG_NAME_7'\n",
    "var='SUB_NAME_7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d45f1-6dd9-44b4-bb31-825db4303234",
   "metadata": {},
   "source": [
    "## Open data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc63b1c-a0e2-4a87-9e20-1e3bdac4733e",
   "metadata": {},
   "source": [
    "## Load ecoregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af90d5f-6226-4e45-a620-40610f89d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(ecoregions_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c061ec0-dac2-4d37-b139-a698d92d174a",
   "metadata": {},
   "source": [
    "## Summarise NDVI over ecoregions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0ecb9-3a32-47c5-9428-f7dd7d4e943f",
   "metadata": {},
   "source": [
    "### Parallelisation version using \"dask.delayed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5cb759-4080-4e09-a20f-d007c010282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decorate the function\n",
    "@dask.delayed\n",
    "def zonal_timeseries(index, ds, gdf, var):\n",
    "    \n",
    "    ds = assign_crs(ds, crs='EPSG:4326')\n",
    "    geom = Geometry(geom=gdf.iloc[index].geometry, crs=gdf.crs)\n",
    "    yy = ds.odc.mask(poly=geom)\n",
    "    yy = yy.dropna(dim='longitude',\n",
    "          how='all').dropna(dim='latitude', how='all')\n",
    "\n",
    "    #summarise into 1d timeseries\n",
    "    yy = yy.mean(['latitude', 'longitude'])\n",
    "    \n",
    "    try:\n",
    "    # ---Interpolate to daily with quadratic function-------\n",
    "        yy = yy.dropna(dim='time',\n",
    "            how='all').resample(time='1D').interpolate(kind='quadratic')\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    return yy\n",
    "\n",
    "#delay open datasets\n",
    "dss = dask.delayed(xr.open_dataarray)(ds_path)\n",
    "gdff = dask.delayed(gpd.read_file)(ecoregions_file)\n",
    "\n",
    "results={}\n",
    "# lazily loop through polygons\n",
    "for index, row in gdf.iterrows():\n",
    "    zz = zonal_timeseries(index, dss, gdff, var)\n",
    "    results[row[var]] = zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79ede0-d3c3-456e-8570-eded5c28734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = dask.compute(results)[0] #bring into memory\n",
    "\n",
    "# remove NaNs\n",
    "results = {k: results[k] for k in results if not type(results[k]) is float}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad8800-89b4-4fab-8398-d89ec9a34396",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872973e-d2fa-430d-8592-9a8420458563",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5351a2-cba2-44d2-b767-fc1ebaeba9f4",
   "metadata": {},
   "source": [
    "### Serialised version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198a4ce-0d18-49cf-9b87-8cf3280ba5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# results={}\n",
    "# i=0\n",
    "# for index, row in gdf[0:20].iterrows():\n",
    "#     print(\"Feature {:02}/{:02}\\r\".format(i + 1, len(range(0, len(gdf)))), end=\"\")\n",
    "    \n",
    "#     #clip to ecoregion\n",
    "#     geom = Geometry(geom=row.geometry, crs=gdf.crs)\n",
    "#     xx = ds_smooth.odc.mask(poly=geom)\n",
    "#     xx = xx.dropna(dim='longitude', how='all').dropna(dim='latitude', how='all')\n",
    "    \n",
    "#     # #summarise into 1d timeseries\n",
    "#     xx = xx.mean(['latitude', 'longitude'])\n",
    "\n",
    "#     #handle case where islands have no NDVI data\n",
    "#     if np.isnan(xx).sum() == len(xx.time):\n",
    "#         i+=1\n",
    "#         continue\n",
    "#     # ---Interpolate to daily with quadratic function-------\n",
    "#     xx = xx.dropna(dim='time', how='all').resample(time='1D').interpolate(kind='quadratic')\n",
    "    \n",
    "#     results[row[var]] = xx\n",
    "    \n",
    "    # i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c56514-2a95-40e4-9db5-6771a93ae4b7",
   "metadata": {},
   "source": [
    "## Using \"multiprocess\"\n",
    "\n",
    "This works, and its fast but it was hanging at the end with only a few polygons to complete. The dask.delayed approach seems more robust, but maybe a little slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ceaa6d-c064-4a17-9e20-9ac6d531fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocess as mp\n",
    "# from tqdm import tqdm\n",
    "# # import geopandas as gpd\n",
    "# # import sys\n",
    "# # from odc.geo.geom import Geometry\n",
    "\n",
    "# def zonal_timeseries(index, var, results):\n",
    "    \n",
    "#     path='/g/data/os22/chad_tmp/Aus_phenology/data/NDVI_smooth.nc'\n",
    "#     ds = assign_crs(xr.open_dataarray(path), crs='EPSG:4326')\n",
    "#     gdff = gpd.read_file(ecoregions_file)\n",
    "    \n",
    "#     geom = Geometry(geom=gdff.iloc[index].geometry, crs=gdff.crs)\n",
    "#     yy = ds.odc.mask(poly=geom)\n",
    "#     yy = yy.dropna(dim='longitude',\n",
    "#           how='all').dropna(dim='latitude', how='all')\n",
    "\n",
    "#     #summarise into 1d timeseries\n",
    "#     yy = yy.mean(['latitude', 'longitude'])\n",
    "    \n",
    "#     try:\n",
    "#     # ---Interpolate to daily with quadratic function-------\n",
    "#         yy = yy.dropna(dim='time',\n",
    "#             how='all').resample(time='1D').interpolate(kind='quadratic')\n",
    "        \n",
    "#         results[gdff.iloc[index][var]] = yy\n",
    "        \n",
    "#     except:\n",
    "#         results[gdff.iloc[index][var]] = np.nan\n",
    "\n",
    "# # parallel function for above function\n",
    "# def _parallel_fun(var, gdf, ncpus):\n",
    "\n",
    "#     manager = mp.Manager()\n",
    "#     results = manager.dict()\n",
    "\n",
    "#     # progress bar\n",
    "#     pbar = tqdm(total=len(gdf))\n",
    "\n",
    "#     def update(*a):\n",
    "#         pbar.update()\n",
    "\n",
    "#     with mp.Pool(ncpus) as pool:\n",
    "#         for index, row in gdf.iterrows():\n",
    "#             pool.apply_async(\n",
    "#                 zonal_timeseries,\n",
    "#                 [index, var, results],\n",
    "#                 callback=update,\n",
    "#             )\n",
    "                \n",
    "#         pool.close()\n",
    "#         pool.join()\n",
    "#         pbar.close()\n",
    "            \n",
    "#     return results\n",
    "\n",
    "# %%time\n",
    "# results = _parallel_fun(var, gdf, ncpus=22)\n",
    "# results = results._getvalue()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
