{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6185d6-5015-4c74-a294-e3c3cea28081",
   "metadata": {},
   "source": [
    "# Extract phenometrics over IBRA subregions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c7445-4b35-4c1a-b586-353f4a293c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from odc.geo.xr import assign_crs\n",
    "from scipy import stats\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import pymannkendall as mk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.interpolate import griddata\n",
    "from odc.geo.geom import Geometry\n",
    "\n",
    "sys.path.append('/g/data/os22/chad_tmp/Aus_phenology/src')\n",
    "from phenology_pixel import _extract_peaks_troughs, xr_phenometrics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f402f2d-ab13-41f3-8442-43722664c9d5",
   "metadata": {},
   "source": [
    "## Analysis Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c27f5-4dbd-40e2-904d-961b23786d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product='AusENDVI-clim_MCD43A4'\n",
    "timeseries_file = '/g/data/os22/chad_tmp/Aus_phenology/data/pickle/IBRA_subregions_NDVI_'+product+'.pkl'\n",
    "save_file = '/g/data/os22/chad_tmp/Aus_phenology/data/pickle/IBRA_subregions_'+product+'_phenometrics_new.pkl'\n",
    "ecoregions_file = '/g/data/os22/chad_tmp/Aus_phenology/data/vectors/IBRAv7_subregions_modified.geojson'\n",
    "var='SUB_NAME_7'\n",
    "region_type = 'IBRA_subregions'\n",
    "years='1982-2022'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d45f1-6dd9-44b4-bb31-825db4303234",
   "metadata": {},
   "source": [
    "## Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1bf71-29b3-4ea7-a9b9-0989f9bfb1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NDVI timeseries processed earlier to daily\n",
    "with open(timeseries_file, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "gdf = gpd.read_file(ecoregions_file)\n",
    "\n",
    "#bare soil NDVI data\n",
    "ss_path = f'/g/data/xc0/project/AusEFlux/data/ndvi_of_baresoil_5km.nc'\n",
    "ss = assign_crs(xr.open_dataarray(ss_path), crs='epsg:4326')\n",
    "ss.name = 'NDVI'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695f636c-237a-4efa-afef-ef87da3e0d19",
   "metadata": {},
   "source": [
    "## Extract phenometrics \n",
    "\n",
    "<!-- import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def double_logistic_function(t, wNDVI, mNDVI, S, A, mS, mA):\n",
    "    sigmoid1 = 1 / (1 + np.exp(-mS * (t - S)))\n",
    "    sigmoid2 = 1 / (1 + np.exp(mA * (t - A)))\n",
    "    seasonal_term = sigmoid1 + sigmoid2 - 1\n",
    "    return wNDVI + (mNDVI - wNDVI) * seasonal_term\n",
    "\n",
    "def weight_function(t, S, A, r):\n",
    "    tr = 100 * (t - S) / (A - S)\n",
    "    tr = np.clip(tr, 0, 100)\n",
    "    return np.exp(-np.abs(r) / (1 + tr / 10))\n",
    "\n",
    "def fit_curve(t, ndvi_observed):\n",
    "    initial_guess = [np.min(ndvi_observed), np.max(ndvi_observed), np.mean(t), np.mean(t), 1, 1]\n",
    "    params, _ = curve_fit(double_logistic_function, t, ndvi_observed, p0=initial_guess, maxfev=10000)\n",
    "    residuals = ndvi_observed - double_logistic_function(t, *params)\n",
    "    weights = weight_function(t, params[2], params[3], residuals)\n",
    "    params, _ = curve_fit(double_logistic_function, t, ndvi_observed, p0=initial_guess, sigma=weights, maxfev=10000)\n",
    "    return params\n",
    "\n",
    "doys = ndvi_cycle.time.dt.dayofyear.values[2:]\n",
    "doys_frac = doys/365\n",
    "values = ndvi_cycle.values[2:]\n",
    "\n",
    "##Fit the curve\n",
    "parameters = fit_curve(doys_frac, values)\n",
    "\n",
    "##Plot the observed NDVI values\n",
    "plt.scatter(doys, values, label='Observed NDVI')\n",
    "\n",
    "##Generate points for the fitted curve\n",
    "t_fit = np.linspace(min(doys_frac), max(doys_frac), 365)\n",
    "ndvi_fit = double_logistic_function(t_fit, *parameters)\n",
    "\n",
    "##Plot the fitted curve\n",
    "plt.plot(t_fit*365, ndvi_fit, label='Fitted Curve', color='red')\n",
    "\n",
    "plt.xlabel('Day of the Year')\n",
    "plt.ylabel('NDVI')\n",
    "plt.legend()\n",
    "plt.title('Double Logistic Curve Fitting for NDVI Observations')\n",
    "plt.show() -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893f740-0438-4503-bcda-00a560009670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pheno={}\n",
    "i=0\n",
    "for index, row in gdf.iterrows():\n",
    "    print(\" {:02}/{:02}\\r\".format(i + 1, len(range(0, len(gdf)))), end=\"\")\n",
    "\n",
    "    if row['SUB_NAME_7'] == 'Coral Se':\n",
    "        continue\n",
    "\n",
    "    if row['SUB_NAME_7'] == 'Timor Sea Coral Islands':\n",
    "        continue\n",
    "    \n",
    "    ds = results[row[var]]\n",
    "\n",
    "    #bare soil NDVI clip to region\n",
    "    geom = Geometry(geom=gdf.iloc[index].geometry, crs=gdf.crs)\n",
    "    soil = ss.odc.mask(poly=geom)\n",
    "    soil = soil.mean().values.item()\n",
    "\n",
    "    # fake expand dims\n",
    "    ds = ds.expand_dims(latitude=[-33.0],longitude=[135.0])\n",
    "    \n",
    "    #apply pheno\n",
    "    p = xr_phenometrics(ds,\n",
    "                    rolling=90,\n",
    "                    distance=90,\n",
    "                    prominence='auto',\n",
    "                    plateau_size=10,\n",
    "                    amplitude=0.2,\n",
    "                    verbose=True,\n",
    "                    soil_signal=0.141,\n",
    "                       ).compute()\n",
    "    \n",
    "    p = p.squeeze().drop_vars(['latitude','longitude']).to_dataframe()\n",
    "    pheno[row['SUB_NAME_7']] = p\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981ae61-381a-4116-9957-767cef698462",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01141218-b62f-4e74-87c1-321bc58bf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(pheno, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2469a-4846-46de-88e4-72975049a29e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
