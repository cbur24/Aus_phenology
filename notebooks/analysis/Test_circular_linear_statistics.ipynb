{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6185d6-5015-4c74-a294-e3c3cea28081",
   "metadata": {},
   "source": [
    "# Testing methods for circular statistics\n",
    "\n",
    "Some theory explanation: \n",
    "\n",
    "- https://bpspsychub.onlinelibrary.wiley.com/doi/full/10.1111/bmsp.12108\n",
    "- https://ebookcentral.proquest.com/lib/anu/reader.action?docID=1679584\n",
    "- https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2017WR021731\n",
    "- https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2014WR016399\n",
    "- https://bg.copernicus.org/articles/17/3991/2020/bg-17-3991-2020.html\n",
    "- https://bpspsychub.onlinelibrary.wiley.com/doi/10.1111/bmsp.12108\n",
    "- https://academic.oup.com/jrsssc/article/65/3/445/7061324?login=true\n",
    "- https://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347(22)00112-4\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.circstd.html#scipy.stats.circstd\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.circmean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c7445-4b35-4c1a-b586-353f4a293c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import circmean, circstd\n",
    "from scipy.stats import pearsonr, chi2\n",
    "from scipy.stats import linregress\n",
    "import pingouin as pg\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "sys.path.append('/g/data/os22/chad_tmp/Aus_phenology/src')\n",
    "from phenology_pixel_circular import mk_with_slopes\n",
    "from LC_regression import circular_model, fit_circular_model, calculate_beta_significance, permutation_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d45f1-6dd9-44b4-bb31-825db4303234",
   "metadata": {},
   "source": [
    "## Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1bf71-29b3-4ea7-a9b9-0989f9bfb1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NDVI timeseries processed earlier to daily\n",
    "timeseries_file = '/g/data/os22/chad_tmp/Aus_phenology/data/pickle/IBRA_subregions_NDVI_AusENDVI-clim_MCD43A4.pkl'\n",
    "with open(timeseries_file, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# phenology calculted earlier\n",
    "phenometrics_file = '/g/data/os22/chad_tmp/Aus_phenology/data/pickle/IBRA_subregions_AusENDVI-clim_MCD43A4_phenometrics_new.pkl'\n",
    "with open(phenometrics_file, 'rb') as f:\n",
    "    eco_regions_phenometrics = pickle.load(f)\n",
    "\n",
    "#ibra subregions\n",
    "ecoregions_file = '/g/data/os22/chad_tmp/Aus_phenology/data/vectors/IBRAv7_subregions_modified.geojson'\n",
    "gdf = gpd.read_file(ecoregions_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9f869-8abe-49fe-8a5d-f996e02a6206",
   "metadata": {},
   "source": [
    "## Interactively plot IBRA regions\n",
    "\n",
    "Hover over the regions to see its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2819e-e7c4-45a3-82f7-da3273d4313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.explore(column='SUB_NAME_7',\n",
    "#             tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "#             attr = 'Esri',\n",
    "#             name = 'Esri Satellite',\n",
    "#             control = True,\n",
    "#             legend=False\n",
    "#            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1c2ad-4b8c-4ba2-841c-4f6259cc4bfc",
   "metadata": {},
   "source": [
    "## Slopes and mean on a time series of circular variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f8f4b-6250-4539-b340-a81f527b0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'West'  # Claraville Plains Eastern Darling Downs rainfed crop Geraldton Hills rainfed crop Highlands-Southern Fall\n",
    "\n",
    "var='EOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9b76f-49ca-48e6-bece-949e57743364",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = results[k] #'Recherche rainfed crop'\n",
    "\n",
    "fig,ax=plt.subplots(1,1, figsize=(15,5))\n",
    "ds.plot(ax=ax, color='tab:blue', linestyle='--', linewidth=1.0, label='Daily NDVI') #.sel(time=slice('1997','2016'))\n",
    "\n",
    "# ax.set_ylim(0.1, 0.9)\n",
    "ax.scatter(x=[pd.to_datetime(d-1, unit='D', origin=str(int(y))) for d,y in zip(eco_regions_phenometrics[k].SOS.values, eco_regions_phenometrics[k].SOS_year.values)],\n",
    "       y=eco_regions_phenometrics[k].vSOS,\n",
    "      c='tab:green', label='SOS', zorder=10)\n",
    "\n",
    "ax.scatter(x=[pd.to_datetime(d-1, unit='D', origin=str(int(y))) for d,y in zip(eco_regions_phenometrics[k].EOS.values, eco_regions_phenometrics[k].EOS_year.values)],\n",
    "       y=eco_regions_phenometrics[k].vEOS,\n",
    "      c='tab:purple', label='EOS', zorder=10)\n",
    "\n",
    "ax.scatter(x=[pd.to_datetime(d-1, unit='D', origin=str(int(y))) for d,y in zip(eco_regions_phenometrics[k].POS.values, eco_regions_phenometrics[k].POS_year.values)],\n",
    "           y=eco_regions_phenometrics[k].vPOS,\n",
    "          c='black', label='POS', zorder=10)\n",
    "\n",
    "ax.scatter(x=[pd.to_datetime(d-1, unit='D', origin=str(int(y))) for d,y in zip(eco_regions_phenometrics[k].TOS.values, eco_regions_phenometrics[k].TOS_year.values)],\n",
    "       y=eco_regions_phenometrics[k].vTOS,\n",
    "      c='tab:orange', label='TOS', zorder=10)\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(None)\n",
    "ax.set_title(k, fontsize=12)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf172b7-ef33-4f9c-9e8b-ac5a98d82324",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = results[k]\n",
    "ds.sel(time=slice('1982','2001')).groupby('time.month').median().plot(label='1982-1999')\n",
    "ds.sel(time=slice('2001','2021')).groupby('time.month').median().plot(label='2001-2021')\n",
    "plt.legend()\n",
    "plt.title(k+' NDVI average annual cycle');\n",
    "# plt.ylim(0.4,0.8)\n",
    "dd = ds.sel(time=slice('2000','2021')).groupby('time.month').mean().data\n",
    "print(find_peaks(dd, prominence=0.005)[0])\n",
    "print('num peaks:', len(find_peaks(dd, prominence=0.005)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6995e066-3e71-4dd1-90c4-bc74fb5858da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from astropy.stats import circmean, circstd\n",
    "from scipy.stats import circmean, circstd\n",
    "import numpy as np\n",
    "\n",
    "def remove_circular_outliers_and_unwrap(\n",
    "    angles,\n",
    "    n_sigma: float = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    Detect outliers in circular data using circular statistics from Astropy and SciPy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    angles : array-like\n",
    "        Angular data in radians\n",
    "    n_sigma : float, optional (default=2.0)\n",
    "        Number of circular standard deviations to use for outlier detection\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    result : Data with outliers removed and np.unwrap applied\n",
    "    \"\"\"\n",
    "    data_copy = angles.copy()\n",
    "    angles = np.asarray(angles)\n",
    "    \n",
    "    # Calculate circular statistics\n",
    "    mean_angle = circmean(angles)\n",
    "    std_angle = circstd(angles)\n",
    "    \n",
    "    # Calculate circular distances from mean\n",
    "    distances = np.abs(np.angle(np.exp(1j * (angles - mean_angle))))\n",
    "    # distances = np.abs(((angles - mean_angle) + np.pi) % (2 * np.pi) - np.pi)\n",
    "\n",
    "    # Identify outliers based on circular standard deviation\n",
    "    outlier_mask = distances > (n_sigma * std_angle)\n",
    "\n",
    "    # Create boolean mask for outliers\n",
    "    # outlier_mask = np.zeros(len(data), dtype=bool)\n",
    "    # outlier_mask[outlier_indices] = True\n",
    "    \n",
    "    # Remove outliers\n",
    "    clean_data = data_copy[~outlier_mask]\n",
    "    \n",
    "    # Apply unwrap to clean data\n",
    "    unwrapped_clean = np.unwrap(clean_data)\n",
    "    \n",
    "    # Create output array filled with nan\n",
    "    result = np.full_like(data_copy, np.nan, dtype=float)\n",
    "    \n",
    "    # Fill in the unwrapped values at non-outlier positions\n",
    "    result[~outlier_mask] = unwrapped_clean\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f551bf1-670a-41d5-beab-409c6c09e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = eco_regions_phenometrics[k]\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"year\": df[f'{var}_year'].values,\n",
    "    \"day_of_year\": df[var].values\n",
    "})\n",
    "\n",
    "# Number of days in a year (adjusting for leap years)\n",
    "data['days_in_year'] = data['year'].apply(lambda y: 366 if y % 4 == 0 and (y % 100 != 0 or y % 400 == 0) else 365)\n",
    "\n",
    "# Convert day-of-year to circular coordinates doy / 365 * 2 * np.pi\n",
    "data['theta'] = data['day_of_year']*((2*np.pi)/data['days_in_year'])\n",
    "\n",
    "# Remove outliers where 1.5 std devs. \n",
    "data['theta_unwrap'] = remove_circular_outliers_and_unwrap(data['theta'], n_sigma=2)\n",
    "\n",
    "# threshold = 275 # Maximum allowable jump before assuming wraparound\n",
    "# data['theta_unwrap'] = np.unwrap(data['theta']) #discont=2*np.pi*threshold/365\n",
    "\n",
    "# Calculate circular mean\n",
    "circular_mean = circmean(data['theta'], nan_policy='omit')\n",
    "circular_std = circstd(data['theta'], nan_policy='omit')\n",
    "\n",
    "circular_mean_doy = circular_mean / (2 * np.pi) * 365\n",
    "circular_std_doy = circular_std / (2 * np.pi) * 365\n",
    "print(f\"Circular mean {var} DOY: {circular_mean_doy}\")\n",
    "print(f\"Circular std. dev. {var} DOY: {circular_std_doy}\")\n",
    "print(f\"Linear mean {var} DOY: {df[var].mean()}\")\n",
    "print(f\"Linear std. dev. {var} DOY: {df[var].std()}\")\n",
    "print('\\n')\n",
    "\n",
    "# find  slope of components as alternative method.\n",
    "# This is bullshit! Can't interprete components seperately according to\n",
    "# https://stats.stackexchange.com/questions/525561/interpreting-multiple-circular-circular-regression-output\n",
    "# When doing linear regression with circular components need to include both the sin and cos components \n",
    "# but can't interpret the beta coefficients seperately.\n",
    "\n",
    "data['x'] = np.cos(data['theta'])\n",
    "data['y'] = np.sin(data['theta'])\n",
    "p_value_x, slope_x, intercept_x = mk_with_slopes(data['x'])\n",
    "p_value_y, slope_y, intercept_y = mk_with_slopes(data['y'])\n",
    "\n",
    "slope_magnitude = np.sqrt(slope_x**2 + slope_y**2)\n",
    "slope_magnitude_doy = slope_magnitude * 365 / (2 * np.pi)\n",
    "\n",
    "# Determine if the trend is toward later (+1) or earlier (-1) dates\n",
    "# Direction near 90° (π/2) means trending later, near 270° (3π/2) means earlier\n",
    "# Calculate the overall direction and magnitude\n",
    "direction = np.arctan2(slope_y, slope_x)\n",
    "trend_direction = 1 if -np.pi/2 < direction < np.pi/2 else -1\n",
    "slope_magnitude_doy *= trend_direction\n",
    "combined_p_value = max(p_value_x, p_value_y)\n",
    "\n",
    "p_value, slope, intercept = mk_with_slopes(data['theta_unwrap'])\n",
    "# slope, intercept, r_value, p_value, std_err = linregress(data.index, data['theta_unwrap'])\n",
    "slope_doy = slope * 365 / (2 * np.pi)\n",
    "\n",
    "print(f\"{var} circular slope magnitude (unwrapped theta): {slope:.4f}\")\n",
    "print(f\"{var} circular slope magnitude (unwrapped theta) converted to DOY units: {slope_doy:.4f}\")\n",
    "# print(f\"{var} circular slope magnitude (x+y): {slope_magnitude:.4f}\")\n",
    "print(f\"{var} circular slope magnitude (x+y) converted to DOY units: {slope_magnitude_doy:.4f}\")\n",
    "print(f\"{var} linear slope magnitude: {mk_with_slopes(df[var]).slope}\")\n",
    "print('\\n')\n",
    "print(f\"{var} circular (unwrapped theta) p-value: {p_value:.4f}\")\n",
    "print(f\"{var} circular (x+y) p-value: {combined_p_value:.4f}\")\n",
    "print(f\"{var} linear p-value: {mk_with_slopes(df[var]).p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bef0c-648e-4f3a-9169-7c77d5ae56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/g/data/os22/chad_tmp/Aus_phenology/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a99909-a0b1-4a5f-96fd-efe6d4dcbd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(5,1, figsize=(9,14), sharex=True)\n",
    "\n",
    "df[var].plot(ax=ax[0])\n",
    "data['theta'].plot(ax=ax[1],label='theta')\n",
    "data['theta_unwrap'].plot(ax=ax[2],label=f'x, slope={slope:.4f}')\n",
    "# ax[2].plot(theta_unwrap,label=f'x, slope={slope:.4f}')\n",
    "data['x'].plot(ax=ax[3],label='x')\n",
    "data['y'].plot(ax=ax[4],label='y')\n",
    "\n",
    "ax[0].grid(alpha=0.75)\n",
    "ax[1].grid(alpha=0.75)\n",
    "ax[2].grid(alpha=0.75)\n",
    "ax[3].grid(alpha=0.75)\n",
    "ax[4].grid(alpha=0.75)\n",
    "ax[0].set_ylabel('DOY')\n",
    "ax[0].set_title(f'{k}: {var} slope={mk_with_slopes(df[var]).slope:.3f} (days/yr), Mean={df[var].mean():.0f} DOY')\n",
    "ax[1].set_title('theta')\n",
    "ax[2].set_title(f'theta unwrapped, slope={slope_doy:.3f} (days/yr), Mean={circular_mean_doy:.0f} DOY');\n",
    "ax[3].set_title('x')\n",
    "ax[4].set_title('y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46eb9f5-3256-43c5-b925-6150a407f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if np.abs(slope_doy) > 3*np.abs(slope_magnitude_doy):\n",
    "#     linear = mk_with_slopes(df[var]).slope\n",
    "#     trend_direction = -1 if linear < 0 else 1\n",
    "#     slope_doy = np.abs(slope_magnitude_doy)*trend_direction\n",
    "#     print(f\"{var} slope magnitude converted to DOY units: {slope_doy:.4f}\")\n",
    "\n",
    "# linear = mk_with_slopes(df[var].squeeze().values)\n",
    "# if np.abs(slope_doy) > 3*np.abs(linear.slope):\n",
    "#     slope_doy = linear.slope\n",
    "#     p_value = linear.p\n",
    "#     print(f\"{var} slope magnitude converted to DOY units: {slope_doy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abc3d6-1b4c-418d-908f-4d592f857a23",
   "metadata": {},
   "source": [
    "## Test func for LC-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554227c8-ee7f-4ac8-8736-d76a7bee2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.index.values\n",
    "x = x-np.mean(x) #centre \n",
    "y_obs = data['theta']\n",
    "weights = np.ones_like(x)  # Equal weights for simplicity\n",
    "\n",
    "# Fit the model\n",
    "optimal_params, objective_value = fit_circular_model(x, y_obs, weights)\n",
    "fitted_mu, fitted_beta = optimal_params\n",
    "\n",
    "# Compute p-value for beta\n",
    "p_value_g = permutation_test(x=x, y_obs=y_obs, weights=weights, fitted_beta=fitted_beta, num_permutations=200)\n",
    "p_value_c = calculate_beta_significance(x, y_obs, weights, kappa=1, wls_weight=0.5)\n",
    "\n",
    "print(f\"Fitted μ: {fitted_mu:.4f}, Fitted β: {fitted_beta:.4f}\", f'Converged in {iter} iterations')\n",
    "print(f\"Fitted DOY μ: {fitted_mu* 365 / (2 * np.pi):.4f}, Fitted DOY β: {fitted_beta* 365 / (2 * np.pi):.4f}\")\n",
    "print(f\"p-value GPT: {p_value_g:.4f}\")\n",
    "print(f\"p-value Claude: {p_value_c:.4f}\")\n",
    "print(f\"linear p-value: {mk_with_slopes(df[var]).p:.4f}\")\n",
    "print(f\"Circular (unwrapped theta) p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf556ce1-3740-4448-88a7-9e8fee0a5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a circular regression model using true mu and beta\n",
    "y_pred = circular_model(fitted_mu, fitted_beta, x)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(11, 4))\n",
    "plt.scatter(x, y_obs*365/(2*np.pi), color='blue', alpha=0.6, label=\"Observed\")\n",
    "plt.plot(x, y_pred*365/(2*np.pi), color='red', linestyle='--', label=\"Fitted Model\", linewidth=2)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Day-of-Year (Radians)\")\n",
    "plt.title(k+\" Circular Regression\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8f3bb-a258-4f03-b86a-74daec9bfa0a",
   "metadata": {},
   "source": [
    "## Test function for circular-linear correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9abe2-12ac-41ff-9783-4924638e8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from scipy.stats import pearsonr, chi2\n",
    "\n",
    "def parcorr_with_circular_vars(data, circular_vars, linear_vars, target_var):\n",
    "    \"\"\"\n",
    "    Calculate partial correlations between variables and a target using pingouin,\n",
    "    properly handling circular variables by decomposing them into sine and cosine components.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): DataFrame containing all variables\n",
    "    circular_vars (list): List of column names for circular variables (in DOY)\n",
    "    linear_vars (list): List of column names for linear variables\n",
    "    target_var (str): Name of the target variable\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Partial correlations with p-values\n",
    "    \"\"\"\n",
    "    # Convert circular variables to sine and cosine components\n",
    "    expanded_data = data.copy()\n",
    "    \n",
    "    for var in circular_vars:\n",
    "        # Convert DOY to radians\n",
    "        radians = 2 * np.pi * (data[var] - 1) / 366\n",
    "        \n",
    "        # Create sine and cosine components\n",
    "        expanded_data[f\"{var}_sin\"] = np.sin(radians)\n",
    "        expanded_data[f\"{var}_cos\"] = np.cos(radians)\n",
    "        \n",
    "        # Drop original circular variable\n",
    "        expanded_data = expanded_data.drop(columns=[var])\n",
    "    \n",
    "    # Create list of all predictor variables\n",
    "    circular_components = [f\"{var}_{comp}\" for var in circular_vars \n",
    "                         for comp in ['sin', 'cos']]\n",
    "\n",
    "    all_predictors = circular_components + linear_vars\n",
    "    \n",
    "    expanded_data = expanded_data[[target_var]+all_predictors]\n",
    "    \n",
    "    # Calculate partial correlation between all vars\n",
    "    results_df = pg.pairwise_corr(expanded_data,\n",
    "            columns=[target_var]) #[[target_var],all_predictors]\n",
    "    \n",
    "    # # Process final results\n",
    "    final_results = []\n",
    "    \n",
    "    # Process linear variables directly\n",
    "    for var in linear_vars:\n",
    "        row = results_df[results_df['Y'] == var].iloc[0]\n",
    "\n",
    "        final_results.append({\n",
    "            'Y': var,\n",
    "            'r': row['r'],\n",
    "            # 'p': row['p-unc']\n",
    "        })\n",
    "    \n",
    "    # Combine sine and cosine components for circular variables\n",
    "    for var in circular_vars:\n",
    "        sin_row = results_df[results_df['Y'] == f\"{var}_sin\"].iloc[0]\n",
    "        cos_row = results_df[results_df['Y'] == f\"{var}_cos\"].iloc[0]\n",
    "        n = len(expanded_data[f\"{var}_cos\"])\n",
    "        \n",
    "        # Calculate magnitude of correlation, reimplementation of here: \n",
    "        # https://pingouin-stats.org/build/html/_modules/pingouin/circular.html#circ_corrcl\n",
    "        rcs = pearsonr(expanded_data[f\"{var}_sin\"], expanded_data[f\"{var}_cos\"])[0]\n",
    "        rxc = cos_row['r']\n",
    "        rxs = sin_row['r']\n",
    "       \n",
    "        r = np.sqrt((rxc**2 + rxs**2 - 2 * rxc * rxs * rcs) / (1-rcs**2))\n",
    "       \n",
    "        # Compute p-value\n",
    "        p_value = chi2.sf(n * r**2, 2)\n",
    "        \n",
    "        final_results.append({\n",
    "            'Y': var,\n",
    "            'r': r,\n",
    "            # 'p': p_value\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(final_results).set_index('Y').transpose().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a4ce7-ac17-4c4c-ad2a-f094a2b5b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable groups\n",
    "circular_vars = ['SOS', 'EOS', 'POS']\n",
    "linear_vars = ['vPOS', 'vSOS', 'vEOS', 'LOS']\n",
    "target_var = 'IOS'\n",
    "\n",
    "# Calculate partial correlations\n",
    "corr_df = parcorr_with_circular_vars(df, circular_vars, linear_vars, target_var)\n",
    "\n",
    "print(corr_df.round(3))\n",
    "\n",
    "# corr_linear_df = pg.pairwise_corr(df, columns=[[target_var], linear_vars+circular_vars])\n",
    "# corr_linear_df = corr_linear_df[['X', 'Y', 'r', 'p-unc']]\n",
    "# corr_linear_df['Abs_Correlation'] = np.abs(corr_linear_df['r'])\n",
    "# corr_linear_df = corr_linear_df.sort_values('Abs_Correlation', ascending=False)\n",
    "# corr_linear_df = corr_linear_df.drop('Abs_Correlation', axis=1)\n",
    "# print(\"\\nPartial Correlations with IOS:\")\n",
    "# print(corr_linear_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01309fd5-8f85-4a99-b8d2-2cdaf92fbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'Otway Ranges' # Claraville Plains Eastern Darling Downs rainfed crop Geraldton Hills rainfed crop\n",
    "\n",
    "ds = eco_regions_phenometrics[k].to_xarray().expand_dims(latitude=[-33.0],longitude=[135.0])\n",
    "\n",
    "template = xr.open_dataset('/g/data/os22/chad_tmp/Aus_phenology/data/templates/template_integral_parcorr.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7af8c-056e-4e84-9521-87d8a481b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phenology_pixel_circular import IOS_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff12985-8a8d-468d-a6b7-132b09f4b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOS_analysis(ds, template=template).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41fbca-cab3-48b4-ad37-be97cecf7707",
   "metadata": {},
   "source": [
    "## Test func for perpixel circular mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a86de3-f08e-41b5-a160-058285155935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.algo._percentile import xr_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643386fb-fb45-4f20-9417-873ab73cab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'Eastern Darling Downs rainfed crop' # Claraville Plains Eastern Darling Downs rainfed crop Geraldton Hills rainfed crop\n",
    "\n",
    "ds = eco_regions_phenometrics[k].to_xarray().expand_dims(latitude=[-33.0],longitude=[135.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb102e83-b25b-42d5-b32a-0ec7fec870e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mean_and_median(ds):\n",
    "    # count number of seasons\n",
    "    # and how many years was this over?\n",
    "    n_seasons = len(ds.index)\n",
    "    \n",
    "    a = ds.POS_year.isel(index=0).values.item()\n",
    "    b = ds.POS_year.isel(index=-1).values.item()\n",
    "    \n",
    "    if np.isnan(a):\n",
    "        n_years=39\n",
    "    else:\n",
    "        n_years = len([i for i in range(int(a),int(b)+1)])\n",
    "    \n",
    "    #first check if its nodata and do a quick mean\n",
    "    # if ds.vPOS.isel(index=0).values.item() == -99.0:\n",
    "    if np.isnan(ds.vPOS.isel(index=0).values.item()):\n",
    "        dd = ds.mean('index')\n",
    "        \n",
    "    else: \n",
    "        #calculate circular statistics for seasonal timings\n",
    "        circ_stats = []\n",
    "        for var in ['SOS', 'POS', 'EOS', 'TOS']:\n",
    "            \n",
    "            data = pd.DataFrame({\n",
    "                \"year\": ds[f'{var}_year'].squeeze().values,\n",
    "                \"day_of_year\": ds[var].squeeze().values\n",
    "            })\n",
    "        \n",
    "            # Number of days in a year (adjusting for leap years)\n",
    "            data['days_in_year'] = data['year'].apply(lambda y: 366 if y % 4 == 0 and (y % 100 != 0 or y % 400 == 0) else 365)\n",
    "            \n",
    "            # Convert day-of-year to circular coordinates doy / 365 * 2 * np.pi\n",
    "            data['theta'] = data['day_of_year']*((2*np.pi)/data['days_in_year'])\n",
    "            data['theta_unwrap'] = np.unwrap(data['theta'])\n",
    "            \n",
    "            # Calculate circular mean, convert back to DOY\n",
    "            circular_mean = circmean(data['theta'], nan_policy='omit')\n",
    "            circular_std = circstd(data['theta'], nan_policy='omit')\n",
    "            circular_mean_doy = circular_mean / (2 * np.pi) * 365\n",
    "            # circular_std_doy = circular_std / (2 * np.pi) * 365\n",
    "        \n",
    "            df = pd.DataFrame({\n",
    "                f'{var}': [circular_mean_doy],\n",
    "                # f'{var}_std': [circular_std_doy],\n",
    "                })\n",
    "        \n",
    "            circ_stats.append(df)\n",
    "\n",
    "        # For the other variables use Kirill's much much faster quantile function (median stats)\n",
    "        dd_circ = pd.concat(circ_stats, axis=1).to_xarray().squeeze().expand_dims(latitude=ds.latitude,longitude=ds.longitude).drop_vars('index')\n",
    "        ds = ds.transpose('index', 'latitude', 'longitude')\n",
    "        other_vars=['vTOS','vSOS','vPOS','vEOS','AOS','LOS','IOS','IOC','LOC','ROG','ROS']\n",
    "        dd_median = xr_quantile(ds[other_vars], quantiles=[0.5], nodata=np.nan)\n",
    "        dd_median = dd_median.sel(quantile=0.5).drop_vars('quantile')\n",
    "        \n",
    "        dd = xr.merge([dd_median, dd_circ]).astype('float32')\n",
    "\n",
    "    # add new variable with number of seasons\n",
    "    dd['n_seasons'] = n_seasons\n",
    "    dd['n_seasons'] = dd['n_seasons'].expand_dims(\n",
    "        latitude=dd.latitude,\n",
    "        longitude=dd.longitude\n",
    "    )\n",
    "    \n",
    "    dd['n_years'] = n_years\n",
    "    dd['n_years'] = dd['n_years'].expand_dims(\n",
    "        latitude=dd.latitude,\n",
    "        longitude=dd.longitude\n",
    "    )\n",
    "    return dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3895acd-ec2b-4fd4-b285-1ba0b6426e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "circular_mean_and_median(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e837c774-3b8c-4e75-a014-f1cb5bd9de45",
   "metadata": {},
   "source": [
    "## Test func for perpixel trend on circular variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd106760-070c-4ae7-9273-019e9609d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phenology_trends(ds, vars):\n",
    "    \"\"\"\n",
    "    Calculate robust statistics over phenology\n",
    "    time series using MannKendal/Theil-Sen.\n",
    "    \"\"\"\n",
    "    slopes=[]\n",
    "    p_values=[]\n",
    "    for var in vars:\n",
    "        if any(var in x for x in ['SOS', 'POS', 'EOS', 'TOS']):\n",
    "            # If variabes are circular, then convert to radians\n",
    "            data = pd.DataFrame({\n",
    "                \"year\": ds[f'{var}_year'].squeeze().values,\n",
    "                \"day_of_year\": ds[var].squeeze().values\n",
    "                })\n",
    "    \n",
    "            # Number of days in a year (adjusting for leap years)\n",
    "            data['days_in_year'] = data['year'].apply(lambda y: 366 if y % 4 == 0 and (y % 100 != 0 or y % 400 == 0) else 365)\n",
    "            \n",
    "            # Convert day-of-year to circular coordinates: doy / 365 * 2 * np.pi\n",
    "            # Then unwrap to deal with calendar crossing and do linear trend on unwrapped theta\n",
    "            data['theta'] = data['day_of_year']*((2*np.pi)/data['days_in_year'])\n",
    "            data['theta_unwrap'] = np.unwrap(data['theta'])\n",
    "            p_value, slope, intercept = mk_with_slopes(data['theta_unwrap'])\n",
    "            slope_doy = slope * 365 / (2 * np.pi)\n",
    "            \n",
    "            # Now check if the componenets slope magnitude is similar\n",
    "            # to the linear slope mangnitude. If they diverge greatly then\n",
    "            # the theta unwrap method has introduced discontinuities and we revert\n",
    "            # to the simple linear method.\n",
    "            linear = mk_with_slopes(ds[var].squeeze().values)\n",
    "            if np.abs(slope_doy) > 3*np.abs(linear.slope):\n",
    "                slope_doy = linear.slope\n",
    "                p_value = linear.p\n",
    "             \n",
    "            df = pd.DataFrame({\n",
    "                f'{var}_slope': [slope_doy],\n",
    "                f'{var}_p_value': [p_value],\n",
    "                })\n",
    "            \n",
    "            dss = df.to_xarray().squeeze().expand_dims(latitude=ds.latitude,longitude=ds.longitude).drop_vars('index')\n",
    "            \n",
    "            slopes.append(dss[f'{var}_slope'])\n",
    "            p_values.append(dss[f'{var}_p_value'])\n",
    "        \n",
    "        else:\n",
    "            # for the other variables take the simple robust slope\n",
    "            # no need to transform into radians\n",
    "            out = xr.apply_ufunc(mk_with_slopes,\n",
    "                          ds[var],\n",
    "                          input_core_dims=[[\"index\"]],\n",
    "                          output_core_dims=[[],[],[],],\n",
    "                          vectorize=True)\n",
    "            \n",
    "            #grab the slopes and p-value\n",
    "            p = out[0].rename(var+'_p_value')\n",
    "            s = out[1].rename(var+'_slope')\n",
    "            # i = out[2].rename(var+'_intercept')\n",
    "        \n",
    "            slopes.append(s)\n",
    "            p_values.append(p)\n",
    "            # intercept.append(i)\n",
    "    \n",
    "        #merge all the variables\n",
    "        slopes_xr = xr.merge(slopes)\n",
    "        p_values_xr = xr.merge(p_values)\n",
    "        # intercept_xr = xr.merge(intercept)\n",
    "\n",
    "    #export a dataset\n",
    "    return xr.merge([slopes_xr,p_values_xr]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb9383-a606-43b1-a7b2-15f334273bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ['SOS', 'POS', 'EOS', 'TOS','vTOS','vSOS','vPOS','vEOS','AOS','LOS','IOS','IOC','LOC','ROG','ROS']\n",
    "\n",
    "dss = phenology_trends(ds, stats)\n",
    "dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114429f1-7eed-4d44-bf92-6fb4b9785125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
