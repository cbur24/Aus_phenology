{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6185d6-5015-4c74-a294-e3c3cea28081",
   "metadata": {},
   "source": [
    "# Extract covariable timeseries over the ecoregions\n",
    "\n",
    "And save to disk as this process is time consuming.\n",
    "Use a hugemem queue.\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "**To Do:**\n",
    "* Consider sourcing climate data from somewhere other than ANUClim, perhaps ERA5 or AGCD, or TerraClimate\n",
    "* Could get some of the climate variables from AusEFlux (SILO, OzWald)\n",
    "* Get burned area from here: https://data.cci.ceda.ac.uk/thredds/catalog/esacci/fire/data/burned_area/AVHRR-LTDR/grid/v1.1/catalog.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c7445-4b35-4c1a-b586-353f4a293c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import warnings\n",
    "import dask\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from odc.geo.xr import assign_crs\n",
    "from odc.geo.geom import Geometry\n",
    "\n",
    "sys.path.append('/g/data/os22/chad_tmp/AusEFlux/src/')\n",
    "from _feature_datasets import _vegetation_fractions\n",
    "from _utils import start_local_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f9f01-d018-4001-ab53-18278062e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_local_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f402f2d-ab13-41f3-8442-43722664c9d5",
   "metadata": {},
   "source": [
    "## Analysis Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c27f5-4dbd-40e2-904d-961b23786d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_file = '/g/data/os22/chad_tmp/Aus_phenology/data/ecoregions_NDVI_timeseries.pkl'\n",
    "# save_file = '/g/data/os22/chad_tmp/Aus_phenology/data/IBRA_regions_NDVI_timeseries.pkl'\n",
    "save_file = '/g/data/os22/chad_tmp/Aus_phenology/data/IBRA_subregions_climate_timeseries.pkl'\n",
    "\n",
    "# ecoregions_file = '/g/data/os22/chad_tmp/Aus_phenology/data/vectors/Ecoregions2017_modified.geojson'\n",
    "# ecoregions_file = '/g/data/os22/chad_tmp/Aus_phenology/data/vectors/IBRAv7_regions_modified.geojson'\n",
    "ecoregions_file = '/g/data/os22/chad_tmp/Aus_phenology/data/vectors/IBRAv7_subregions_modified.geojson'\n",
    "\n",
    "# var='ECO_NAME'\n",
    "# var='REG_NAME_7'\n",
    "var='SUB_NAME_7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6096af-0efe-4f0a-88d7-cc193cd512c2",
   "metadata": {},
   "source": [
    "## Load climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c51f0-dcb2-4357-8501-976556a00068",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clim = '/g/data/os22/chad_tmp/AusENDVI/data/5km/'\n",
    "co2 = xr.open_dataset(base_clim+'CO2_5km_monthly_1982_2022.nc')\n",
    "rain = xr.open_dataset(base_clim+'rain_5km_monthly_1981_2022.nc').sel(time=slice('1982','2022')).drop_vars('spatial_ref')\n",
    "srad = xr.open_dataset(base_clim+'srad_5km_monthly_1982_2022.nc').drop_vars('spatial_ref')\n",
    "tavg = xr.open_dataset(base_clim+'tavg_5km_monthly_1982_2022.nc').drop_vars('spatial_ref')\n",
    "vpd = xr.open_dataset(base_clim+'vpd_5km_monthly_1982_2022.nc').drop_vars('spatial_ref')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562bfcc-d53b-4c54-8dbf-1548f49f4b21",
   "metadata": {},
   "source": [
    "## Calculate tree fractions\n",
    "\n",
    "This will be our measure of woody encroachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9044f46-3303-4a4e-80eb-89ac5cf79e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "results='/g/data/os22/chad_tmp/Aus_phenology/data/'\n",
    "ndvi_path='/g/data/os22/chad_tmp/AusENDVI/results/publication/AusENDVI-clim_MCD43A4_gapfilled_1982_2022.nc'\n",
    "ndvi_min='/g/data/os22/chad_tmp/AusEFlux/data/ndvi_of_baresoil_5km.nc'\n",
    "ndvi_max=0.91\n",
    "dask_chunks={'latitude': 250, 'longitude': 250, 'time': -1}\n",
    "\n",
    "# NDVI value of bare soil (supplied by Luigi Renzullo)\n",
    "ndvi_min = xr.open_dataarray(ndvi_min,\n",
    "                            chunks=dict(latitude=dask_chunks['latitude'],\n",
    "                            longitude=dask_chunks['longitude'])\n",
    "                            )\n",
    "#ndvi data is here\n",
    "ds = xr.open_dataset(ndvi_path, chunks=dask_chunks)\n",
    "ds = ds.rename({'AusENDVI_clim_MCD43A4':'NDVI'})\n",
    "ds = ds['NDVI']\n",
    "\n",
    "#calculate f-total\n",
    "ft = (ds - ndvi_min) / (ndvi_max - ndvi_min)\n",
    "ft = xr.where(ft<0, 0, ft)\n",
    "ft = xr.where(ft>1, 1, ft)\n",
    "\n",
    "#calculate initial persistent fraction (equation 1 & 2 in Donohue 2009)\n",
    "persist = ft.rolling(time=7, min_periods=1).min()\n",
    "persist = persist.rolling(time=9, min_periods=1).mean()\n",
    "\n",
    "#calculate initial recurrent fraction (equation 3 in Donohue 2009)\n",
    "recurrent = ft - persist\n",
    "\n",
    "###------- equations 4 & 5 in Donohue 2009----------------\n",
    "persist = xr.where(recurrent<0, persist - np.abs(recurrent), persist) #eq4\n",
    "recurrent = ft - persist # eq 5\n",
    "## ---------------------------------------------------------\n",
    "\n",
    "#ensure values are between 0 and 1\n",
    "persist = xr.where(persist<0, 0, persist)\n",
    "recurrent = xr.where(recurrent<0, 0, recurrent)\n",
    "\n",
    "#assign variable names\n",
    "recurrent.name='grass'\n",
    "persist.name='trees'\n",
    "\n",
    "# Aggregate to annual layers\n",
    "# Use the maximum fraction of trees and grass to create annual layers.\n",
    "# Bare soil is the residual\n",
    "persist_annual = persist.resample(time='1Y').max().compute()\n",
    "recurrent_annual = recurrent.resample(time='1Y').max().compute()\n",
    "bare_annual = 1-(persist_annual+recurrent_annual)\n",
    "bare_annual.name='bare'\n",
    "\n",
    "#create a monthly timeseries (same vale for each month within a year)\n",
    "dss_trees=[]\n",
    "dss_grass=[]\n",
    "dss_bare=[]\n",
    "for y in bare_annual.time.dt.year.values:\n",
    "    # print(y)\n",
    "    y = str(y)\n",
    "    time = pd.date_range(y+\"-01\", y+\"-12\", freq='MS') \n",
    "    time = [t+pd.Timedelta(14, 'd') for t in time]\n",
    "\n",
    "    #trees\n",
    "    ds_persist = persist_annual.sel(time=y).squeeze().drop('time')\n",
    "    ds_persist = ds_persist.expand_dims(time=time)\n",
    "    dss_trees.append(ds_persist)\n",
    "\n",
    "    #grass\n",
    "    ds_recurrent = recurrent_annual.sel(time=y).squeeze().drop('time')\n",
    "    ds_recurrent = ds_recurrent.expand_dims(time=time)\n",
    "    dss_grass.append(ds_recurrent)\n",
    "\n",
    "    ds_bare = bare_annual.sel(time=y).squeeze().drop('time')\n",
    "    ds_bare = ds_bare.expand_dims(time=time)\n",
    "    dss_bare.append(ds_bare)\n",
    "\n",
    "# join all the datasets back together\n",
    "trees = xr.concat(dss_trees, dim='time').sortby('time')\n",
    "\n",
    "# add right metadata\n",
    "trees.attrs['nodata'] = np.nan\n",
    "trees = assign_crs(trees, crs='EPSG:4326')\n",
    "#export\n",
    "# trees.to_netcdf(results+'trees_5km.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0750e89-9c63-4024-9363-341c3fe8d991",
   "metadata": {},
   "source": [
    "## Merge all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b36a98-8f0d-4338-9dd5-64dcc9300eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = xr.merge([co2, rain, srad, tavg, vpd, trees])\n",
    "covars = assign_crs(covars, crs='EPSG:4326')\n",
    "covars = covars.transpose('time', 'latitude','longitude')\n",
    "covars = covars.sel(time=slice('1982', '2022'))\n",
    "\n",
    "for v in covars.data_vars:\n",
    "    try:\n",
    "        del covars[v].attrs['grid_mapping']\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38fdd5-bd70-476b-bbdf-3f1ce64626fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covars['vpd'].isel(time=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efdddcc-848c-4270-a80e-c7a02e9f73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk for multiprocessing next\n",
    "covars.to_netcdf('/g/data/os22/chad_tmp/Aus_phenology/data/covars.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35bf8e-f0c9-40bf-a484-56a2bd00d0dc",
   "metadata": {},
   "source": [
    "### Summarise covariables data over polygons\n",
    "\n",
    "Slow so using Dask to multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3c618-aaa3-4a01-a706-27258dfb7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(ecoregions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f57515-a479-40eb-8e46-e2d765758365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decorate the function\n",
    "@dask.delayed\n",
    "def clim_zonal_timeseries(index, ds, gdf, var):\n",
    "    \n",
    "    ds = assign_crs(ds, crs='EPSG:4326')\n",
    "    geom = Geometry(geom=gdf.iloc[index].geometry, crs=gdf.crs)\n",
    "    yy = ds.odc.mask(poly=geom)\n",
    "    yy = yy.dropna(dim='longitude',\n",
    "          how='all').dropna(dim='latitude', how='all')\n",
    "\n",
    "    #summarise into 1d timeseries\n",
    "    yy = yy.mean(['latitude', 'longitude'])\n",
    "\n",
    "    if np.isnan(yy['rain']).sum() == len(yy.time):\n",
    "        yy=np.nan\n",
    "\n",
    "    return yy\n",
    "\n",
    "#delay open datasets\n",
    "path='/g/data/os22/chad_tmp/Aus_phenology/data/covars.nc'\n",
    "dss = dask.delayed(xr.open_dataset)(path)\n",
    "gdff = dask.delayed(gpd.read_file)(ecoregions_file)\n",
    "\n",
    "results_clim={}\n",
    "# lazily loop through polygons\n",
    "for index, row in gdf.iterrows():\n",
    "    zz = clim_zonal_timeseries(index, dss, gdff, var)\n",
    "    results_clim[row[var]] = zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346d99f-3718-47df-a535-623bdbf82877",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_clim = dask.compute(results_clim)[0] #bring into memory\n",
    "\n",
    "# remove NaNs\n",
    "results_clim = {k: results_clim[k] for k in results_clim if not type(results_clim[k]) is float}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f49d4a-cbb3-41b7-98b4-1dab983d94b5",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629edef-5a93-4d38-a8fb-d5258d44df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(results_clim, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ea780-edbc-43ec-9182-f795705fc879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
