{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b43d99-d698-40b4-a6cb-1e205a6cc0d7",
   "metadata": {},
   "source": [
    "# Per pixel phenology across Australia\n",
    "\n",
    "This is very compute heavy and we can only return summaries (long term average, and/or trends), but it works and gives robust phenometrics for Aus.\n",
    "\n",
    "Use a large local dask cluster, recommend `normalsr` queue and `104 cpus 496 GiB`, will take about 10 hours to loop through the 8 tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a23e7-5a01-4839-a9c2-f02880a81e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import dask\n",
    "import dask.array\n",
    "from dask import delayed\n",
    "\n",
    "import seaborn as sb\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from odc.geo.xr import assign_crs\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/Aus_phenology/src')\n",
    "from phenology_pixel import xr_phenometrics, phenology_trends, _mean\n",
    "\n",
    "sys.path.append('/g/data/os22/chad_tmp/AusEFlux/src/')\n",
    "from _utils import round_coords\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304396c-c266-48cd-a707-e1dbca45d307",
   "metadata": {},
   "source": [
    "## Dask cluster\n",
    "\n",
    "Local or Dynamic?\n",
    "\n",
    "Dyanamic can be fickle so stick with local for now\n",
    "\n",
    "https://github.com/NCI900-Training-Organisation/Distributed-Dask-Cluster-on-Gadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881177a6-0576-4ea2-a920-08193a096dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/g/data/os22/chad_tmp/AusEFlux/src/')\n",
    "from _utils import start_local_dask\n",
    "start_local_dask(n_workers=102, threads_per_worker=1, memory_limit='440GiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6a5f6-5bea-48af-8b7f-1ceaab3b7904",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# from dask_jobqueue import PBSCluster\n",
    "\n",
    "# cpus=52\n",
    "# mem='240GB'\n",
    "# extra = ['-q normalsr',\n",
    "#          '-P w97', \n",
    "#          '-l ncpus='+str(cpus), \n",
    "#          '-l mem='+mem,\n",
    "#         '-l storage=gdata/os22+gdata/w97'\n",
    "#         ]\n",
    "# setup_commands = [\"module load python3/3.10.0\", \"source /g/data/os22/chad_tmp/AusENDVI/env/py310/bin/activate\"]\n",
    "\n",
    "# cluster = PBSCluster(walltime=\"01:00:00\", \n",
    "#                      cores=cpus,\n",
    "#                      processes=cpus,\n",
    "#                      memory=mem,\n",
    "#                      shebang='#!/usr/bin/env bash',\n",
    "#                      job_extra_directives=extra, \n",
    "#                      local_directory='/g/data/os22/chad_tmp/Aus_phenology/data', \n",
    "#                      job_directives_skip=[\"select\"], \n",
    "#                      interface=\"ib0\",\n",
    "#                      job_script_prologue=setup_commands,\n",
    "#                     )\n",
    "\n",
    "# # print(cluster.job_script())\n",
    "# cluster.scale(jobs=1)\n",
    "# client = Client(cluster)\n",
    "# client\n",
    "\n",
    "# client.shutdown()\n",
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b77dc-62cc-445f-b650-72d104c6d175",
   "metadata": {},
   "source": [
    "## Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7391fc-5c9d-41fb-ad27-342d2badb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/g/data/os22/chad_tmp/Aus_phenology/data/NDVI/NDVI_smooth_AusENDVI-clim_MCD43A4.nc')['NDVI']\n",
    "\n",
    "#testing slices\n",
    "# ds = ds.isel(latitude=slice(200,352), longitude=slice(50,302))\n",
    "# ds = ds.isel(latitude=slice(400,425), longitude=slice(100,125))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5431ff9-08fd-4f58-a717-52f15d242139",
   "metadata": {},
   "source": [
    "### Split data into tiles\n",
    "\n",
    "Running all of Aus just takes too long, >500,000 pixels * > 14,000 time steps - dask graph is huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e72dd-43e9-4fdc-9111-434c4a11a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split into spatial tiles\n",
    "def split_spatial_tiles(data_array, lat_dim='latitude', lon_dim='longitude', n_lat=2, n_lon=4):\n",
    "    lat_size = data_array.sizes[lat_dim] // n_lat\n",
    "    lon_size = data_array.sizes[lon_dim] // n_lon\n",
    "    \n",
    "    tiles = []\n",
    "    for i in range(n_lat):\n",
    "        for j in range(n_lon):\n",
    "            tile = data_array.isel({\n",
    "                lat_dim: slice(i * lat_size, (i + 1) * lat_size),\n",
    "                lon_dim: slice(j * lon_size, (j + 1) * lon_size)\n",
    "            })\n",
    "            tiles.append(tile)\n",
    "    \n",
    "    return tiles\n",
    "\n",
    "\n",
    "# Split data into spatial tiles (2 latitude x 4 longitude)\n",
    "tiles = split_spatial_tiles(ds, n_lat=2, n_lon=4)\n",
    "\n",
    "#verify no overlaps or missing pixels.\n",
    "assert np.sum(xr.combine_by_coords(tiles).longitude == ds.longitude) == len(ds.longitude)\n",
    "assert np.sum(xr.combine_by_coords(tiles).latitude == ds.latitude) == len(ds.latitude)\n",
    "\n",
    "# create named dictonary\n",
    "tile_names=['NW', 'NNW', 'NNE', 'NE',\n",
    "            'SW', 'SSW', 'SSE', 'SE']\n",
    "tiles_dict = dict(zip(tile_names, tiles))\n",
    "\n",
    "#create a plot to visualise tiles\n",
    "fig,axes = plt.subplots(2, 4, figsize=(10,8))\n",
    "for t,ax in zip(tiles, axes.ravel()):\n",
    "    t.isel(time=range(0,20)).mean('time').plot(ax=ax, add_colorbar=False, add_labels=False)\n",
    "    ax.set_title(None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c85896-5100-41ac-a7e3-43d11e948099",
   "metadata": {},
   "source": [
    "## Per pixel phenometrics with dask.delayed\n",
    "\n",
    "Loop through the eight tiles and compute the phenometerics, the average phenometrics, and the trends in phenometrics.\n",
    "\n",
    "The tiles can be combined therafter to have our continental per pixel phenology.\n",
    "\n",
    "https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f7b48-42c7-4799-bbd6-a614475177ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n,d in tiles_dict.items():\n",
    "    \n",
    "    if os.path.exists(f'/g/data/os22/chad_tmp/Aus_phenology/results/pheno_tiles/aus_trends_phenology_perpixel_{n}.nc'):\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        print('Working on tile: '+ n)\n",
    "        \n",
    "        ### --------Handle NaNs---------\n",
    "        # Due to issues with xarray quadratic interpolation, we need to remove\n",
    "        # every NaN or else the daily interpolation function will fail\n",
    "        \n",
    "        ##remove last ~6 timesteps that are all-NaN (from S-G smoothing).\n",
    "        times_to_keep = d.mean(['latitude','longitude']).dropna(dim='time',how='any').time\n",
    "        d = d.sel(time=times_to_keep)\n",
    "        \n",
    "        #Find where NaNs are >10 % of data, will use this mask to remove pixels later.\n",
    "        nan_mask = np.isnan(d).sum('time') >= len(d.time) / 10\n",
    "        # nan_mask.to_netcdf(f'/g/data/os22/chad_tmp/Aus_phenology/data/ndvi_tiles/nan_mask_{n}.nc')\n",
    "        \n",
    "        #fill the mostly all NaN slices with a fill value\n",
    "        d = xr.where(nan_mask, -99, d)\n",
    "        \n",
    "        #interpolate away any remaining NaNs\n",
    "        d = d.interpolate_na(dim='time', method='cubic', fill_value=\"extrapolate\")\n",
    "        \n",
    "        #now we can finally interpolate to daily\n",
    "        d = d.resample(time='1D').interpolate(kind='quadratic').astype('float32')\n",
    "        \n",
    "        #export so in the next step we can import the array with dask.delayed\n",
    "        # d.to_netcdf(f'/g/data/os22/chad_tmp/Aus_phenology/data/ndvi_tiles/ndvi_{n}.nc')\n",
    "    \n",
    "        ### --------Calculate the phenometrics on each pixel--------\n",
    "        #                Paralleized with dask.delayed.\n",
    "        \n",
    "        # Lazily open the NDVI data\n",
    "        # path=f'/g/data/os22/chad_tmp/Aus_phenology/data/ndvi_tiles/ndvi_{n}.nc'\n",
    "        # da=dask.delayed(xr.open_dataarray)(path)\n",
    "    \n",
    "        # We also need the shape of the stacked array\n",
    "        shape = d.stack(spatial=('latitude', 'longitude')).values.shape\n",
    "        \n",
    "        #stack spatial indexes, this makes it easy to loop through data\n",
    "        y_stack = d.stack(spatial=('latitude', 'longitude'))\n",
    "        Y = y_stack.transpose('time', 'spatial')\n",
    "        \n",
    "        #find spatial indexes where values are mostly NaN (mostly land-sea mask)\n",
    "        # This is where the nan_mask we created earlier = True\n",
    "        idx_all_nan = np.where(nan_mask.stack(spatial=('latitude', 'longitude'))==True)[0]\n",
    "        \n",
    "        # open template array which we'll use \n",
    "        # whenever we encounter an all-NaN index.\n",
    "        # Created the template using one of the output results\n",
    "        # bb = xr.full_like(results[0], fill_value=-99, dtype='float32')\n",
    "        template_path='/g/data/os22/chad_tmp/Aus_phenology/data/template.nc'\n",
    "        ds_template = xr.open_dataset(template_path)\n",
    "    \n",
    "        #now we start the real proceessing\n",
    "        results=[]\n",
    "        for i in range(shape[1]): #loop through all spatial indexes.\n",
    "        \n",
    "            #select pixel\n",
    "            data = Y.isel(spatial=i)\n",
    "            \n",
    "            # First, check if spatial index has data. If its one of \n",
    "            # the all-NaN indexes then return xarray filled with -99 values\n",
    "            if i in idx_all_nan:\n",
    "                xx = ds_template.copy() #use our template    \n",
    "                xx['latitude'] = [data.latitude.values.item()] #update coords\n",
    "                xx['longitude'] = [data.longitude.values.item()]\n",
    "            \n",
    "            else:\n",
    "                xx = xr_phenometrics(data,\n",
    "                                  rolling=90,\n",
    "                                  distance=90,\n",
    "                                  prominence='auto',\n",
    "                                  plateau_size=10,\n",
    "                                  amplitude=0.20\n",
    "                                 )\n",
    "        \n",
    "            #append results, either data or all-zeros\n",
    "            results.append(xx)\n",
    "        \n",
    "        # #bring into memory this will take a long time\n",
    "        # with warnings.catch_warnings(): #(can't suppress pandas warnings!)\n",
    "        warnings.filterwarnings(\"ignore\", category=FutureWarning,  module=\"pandas\")\n",
    "        results = dask.persist(results)[0]\n",
    "        \n",
    "        # ### ----Summarise phenology with a median------------\n",
    "        #now we need to compute the average phenology\n",
    "        p_average = [_mean(x) for x in results]\n",
    "        p_average = dask.compute(p_average)[0]\n",
    "        p_average = xr.combine_by_coords(p_average)\n",
    "        \n",
    "        #remove NaN areas that have a fill value\n",
    "        p_average = p_average.where(p_average>-99).astype('float32')\n",
    "        p_average = p_average.where(~np.isnan(p_average.vPOS)) #and again for the n_seasons layer\n",
    "        p_average = assign_crs(p_average, crs='EPSG:4326') # add geobox\n",
    "    \n",
    "        #export results\n",
    "        p_average.to_netcdf(f'/g/data/os22/chad_tmp/Aus_phenology/results/pheno_tiles/aus_mean_phenology_perpixel_{n}.nc')\n",
    "    \n",
    "        ### ----Find the trends in phenology--------------\n",
    "        #now find trends in phenometrics\n",
    "        trend_vars = ['POS','vPOS','TOS','vTOS','AOS','SOS',\n",
    "                      'vSOS','EOS','vEOS','LOS','IOS','ROG','ROS']\n",
    "        p_trends = [phenology_trends(x, trend_vars) for x in results]\n",
    "        p_trends = dask.compute(p_trends)[0]\n",
    "        p_trends = xr.combine_by_coords(p_trends)\n",
    "        \n",
    "        #remove NaNs\n",
    "        p_trends = p_trends.where(~np.isnan(p_average.vPOS)).astype('float32')\n",
    "        \n",
    "        #assign crs and export\n",
    "        p_trends = assign_crs(p_trends, crs='EPSG:4326')\n",
    "        p_trends.to_netcdf(f'/g/data/os22/chad_tmp/Aus_phenology/results/pheno_tiles/aus_trends_phenology_perpixel_{n}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57f0af-0b7e-40b7-9713-a3d5a79447a3",
   "metadata": {},
   "source": [
    "## Join tiles together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560dd06-ffff-48c5-8c47-c906a8ba9a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_path = '/g/data/os22/chad_tmp/Aus_phenology/results/pheno_tiles/'\n",
    "trend_tiles = [tiles_path+i for i in os.listdir(tiles_path) if 'trends' in i]\n",
    "trend_tiles = [xr.open_dataset(t) for t in trend_tiles]\n",
    "\n",
    "p_trends = xr.combine_by_coords(trend_tiles)\n",
    "p_trends = assign_crs(p_trends,crs='EPSG:4326')\n",
    "\n",
    "for var in p_trends.data_vars:\n",
    "    del p_trends[var].attrs['grid_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd1cd3-db41-4992-9d08-b57d443e6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tiles = [tiles_path+i for i in os.listdir(tiles_path) if 'mean' in i]\n",
    "mean_tiles = [xr.open_dataset(t) for t in mean_tiles]\n",
    "\n",
    "p_average = xr.combine_by_coords(mean_tiles)\n",
    "p_average = assign_crs(p_average,crs='EPSG:4326')\n",
    "\n",
    "for var in p_average.data_vars:\n",
    "    del p_average[var].attrs['grid_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a0341-b792-4ba4-97f3-f07b29c04bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_average.n_seasons.plot(cmap='RdYlBu', vmin=34, vmax=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940cebe3-ce05-461f-b9d6-183bcd93db5e",
   "metadata": {},
   "source": [
    "## Mask urban, water, irrigated regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640ff92-def2-4746-957f-bc0a61009488",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = xr.open_dataset('/g/data/os22/chad_tmp/Aus_phenology/data/croplands_5km.nc')['croplands']\n",
    "crops = xr.where(crops==2, 0, 1) #irrigated crops\n",
    "crops = round_coords(crops)\n",
    "\n",
    "urban = xr.open_dataarray('/g/data/os22/chad_tmp/AusEFlux/data/urban_mask_5km.nc').rename({'y':'latitude','x':'longitude'})\n",
    "urban = ~urban\n",
    "\n",
    "water = xr.open_dataarray('/g/data/os22/chad_tmp/Aus_phenology/data/NVISv6_5km.nc') ##24=inland water\n",
    "water = xr.where(water==24,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d0ba9-5751-473f-b641-799dc2731c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_trends = (urban & crops & water)\n",
    "mask_average = (urban & water) #long-term average is okay for irrigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306a17b-09ba-4755-9b3b-fee9ad5fb11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_trends = p_trends.where(mask_trends)\n",
    "p_average = p_average.where(mask_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2068041-950d-4057-aefb-516a3a4f78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_trends['vPOS_slope'].odc.explore(\n",
    "#             tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "#            attr = 'Esri',\n",
    "#            name = 'Esri Satellite'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bd19c-49f3-447c-9e99-aae65b4bb959",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11967d-6491-4109-b074-5d844c4c7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_average.to_netcdf('/g/data/os22/chad_tmp/Aus_phenology/results/aus_mean_phenology_perpixel.nc')\n",
    "p_trends.to_netcdf('/g/data/os22/chad_tmp/Aus_phenology/results/aus_trends_phenology_perpixel.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
